{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\"Intervention__HASH__Vaccine-preventable-disease__HASH__Rotaviru\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User selection: efficacy\n",
      "Checking column: Newborn_0-1\n",
      "Display: Newborn_0-1, Synonyms: ['newborn', 'babies', 'baby', 'infant', 'toddlers', 'young ones', 'youngsters', 'small children', 'Newborn_0-1']\n",
      "Checking column: Children_2-9\n",
      "Display: Children_2-9, Synonyms: ['child', 'children', 'Children_2-9']\n",
      "Checking column: Adolescents_10-17\n",
      "Display: Adolescents_10-17, Synonyms: ['adolescents', 'adolescent', 'young adults', 'Adolescents_10-17']\n",
      "Checking column: Adults_18-64\n",
      "Display: Adults_18-64, Synonyms: ['adults', 'adult', 'Adults_18-64']\n",
      "Checking column: OlderAdults_65-10000\n",
      "Display: OlderAdults_65-10000, Synonyms: ['elderly', 'older adults', 'OlderAdults_65-10000']\n",
      "Checking column: HealthcareWorkers\n",
      "Display: HealthcareWorkers, Synonyms: ['Physician', 'Nurse', 'Surgeon', 'Dentist', 'Pharmacist', 'Physical Therapist', 'Occupational Therapist', 'Medical Laboratory Technologist', 'Radiologist', 'Dietitian/Nutritionist', 'Respiratory Therapist', 'Speech-Language Pathologist', 'Physician Assistant', 'Nurse Practitioner', 'Certified Nursing Assistant (CNA)', 'Medical Assistant', 'Paramedic/EMT', 'Midwife', 'Psychologist', 'Social Worker (Clinical)', 'Hospital Administrator', 'Medical Researcher', 'Health Educator', 'Orthopedic Technician', 'Optometrist', 'Podiatrist', 'Anesthesiologist', 'Neurologist', 'Cardiologist', 'Gastroenterologist', 'HealthcareWorkers']\n",
      "Checking column: PregnantWomen\n",
      "Display: PregnantWomen, Synonyms: ['pregnant', 'pregnant women', 'PregnantWomen']\n",
      "Checking column: Travellers\n",
      "Display: Travellers, Synonyms: ['traveller', 'Travellers']\n",
      "Checking column: ParentsCaregivers\n",
      "Display: ParentsCaregivers, Synonyms: ['parents', 'caregivers', 'ParentsCaregivers']\n",
      "Checking column: Immunocompromised\n",
      "Display: Immunocompromised, Synonyms: ['immunocompromised', 'Immunocompromised']\n",
      "Checking column: Healthy\n",
      "Display: Healthy, Synonyms: ['healthy', 'Healthy']\n",
      "Checking column: Efficacy-Effectiveness\n",
      "Display: Efficacy-Effectiveness, Synonyms: ['effectiveness', 'impact of', 'effectiveness of', 'efficacy', 'Efficacy-Effectiveness']\n",
      "Matched synonym: efficacy\n",
      "Result: Topic__HASH__Efficacy-Effectiveness__HASH__Efficacy-Effectiveness\n"
     ]
    }
   ],
   "source": [
    "def map_user_selection_to_column(user_selection, structured_data):\n",
    "    \"\"\"\n",
    "    Maps a user's selection to the corresponding column name for database search.\n",
    "\n",
    "    :param user_selection: The term or keyword selected by the user (e.g., \"efficacy\").\n",
    "    :param structured_data: The structured dictionary containing mappings of display values and synonyms.\n",
    "    :return: The original column name from filtered_columns or None if no match is found.\n",
    "    \"\"\"\n",
    "    # Ensure user_selection is lowercased for case-insensitive comparison\n",
    "    user_selection_lower = user_selection.lower()\n",
    "    print(f\"User selection: {user_selection_lower}\")  # Debugging user input\n",
    "\n",
    "    for category, subgroups in structured_data.items():\n",
    "        if not isinstance(subgroups, dict):\n",
    "            print(f\"Skipping invalid subgroups in category {category}\")\n",
    "            continue\n",
    "        for subgroup, values in subgroups.items():\n",
    "            if not isinstance(values, dict):\n",
    "                print(f\"Skipping invalid values in subgroup {subgroup}\")\n",
    "                continue\n",
    "            for column_name, details in values.items():\n",
    "                if not isinstance(details, dict) or \"display\" not in details or \"synonyms\" not in details:\n",
    "                    print(f\"Skipping invalid details for column {column_name}\")\n",
    "                    continue\n",
    "\n",
    "                # Debugging comparisons\n",
    "                print(f\"Checking column: {column_name}\")\n",
    "                print(f\"Display: {details['display']}, Synonyms: {details['synonyms']}\")\n",
    "\n",
    "                # Match against display\n",
    "                if user_selection_lower == details[\"display\"].lower():\n",
    "                    print(f\"Matched display: {details['display']}\")\n",
    "                    return f\"{category}__HASH__{subgroup}__HASH__{column_name}\"\n",
    "\n",
    "                # Match against synonyms\n",
    "                if user_selection_lower in [syn.lower() for syn in details[\"synonyms\"]]:\n",
    "                    print(f\"Matched synonym: {user_selection_lower}\")\n",
    "                    return f\"{category}__HASH__{subgroup}__HASH__{column_name}\"\n",
    "\n",
    "    # If no match is found\n",
    "    print(f\"No match found for user selection: {user_selection_lower}\")\n",
    "    return None\n",
    "\n",
    "\n",
    "user_selection = \"efficacy\"\n",
    "structured_data = {'Population': {'AgeGroup': {'Newborn_0-1': {'display': 'Newborn_0-1', 'synonyms': ['newborn', 'babies', 'baby', 'infant', 'toddlers', 'young ones', 'youngsters', 'small children', 'Newborn_0-1'], 'additional_context': None}, 'Children_2-9': {'display': 'Children_2-9', 'synonyms': ['child', 'children', 'Children_2-9'], 'additional_context': None}, 'Adolescents_10-17': {'display': 'Adolescents_10-17', 'synonyms': ['adolescents', 'adolescent', 'young adults', 'Adolescents_10-17'], 'additional_context': None}, 'Adults_18-64': {'display': 'Adults_18-64', 'synonyms': ['adults', 'adult', 'Adults_18-64'], 'additional_context': None}, 'OlderAdults_65-10000': {'display': 'OlderAdults_65-10000', 'synonyms': ['elderly', 'older adults', 'OlderAdults_65-10000'], 'additional_context': None}}, 'SpecificGroup': {'HealthcareWorkers': {'display': 'HealthcareWorkers', 'synonyms': ['Physician', 'Nurse', 'Surgeon', 'Dentist', 'Pharmacist', 'Physical Therapist', 'Occupational Therapist', 'Medical Laboratory Technologist', 'Radiologist', 'Dietitian/Nutritionist', 'Respiratory Therapist', 'Speech-Language Pathologist', 'Physician Assistant', 'Nurse Practitioner', 'Certified Nursing Assistant (CNA)', 'Medical Assistant', 'Paramedic/EMT', 'Midwife', 'Psychologist', 'Social Worker (Clinical)', 'Hospital Administrator', 'Medical Researcher', 'Health Educator', 'Orthopedic Technician', 'Optometrist', 'Podiatrist', 'Anesthesiologist', 'Neurologist', 'Cardiologist', 'Gastroenterologist', 'HealthcareWorkers'], 'additional_context': None}, 'PregnantWomen': {'display': 'PregnantWomen', 'synonyms': ['pregnant', 'pregnant women', 'PregnantWomen'], 'additional_context': None}, 'Travellers': {'display': 'Travellers', 'synonyms': ['traveller', 'Travellers'], 'additional_context': None}, 'ParentsCaregivers': {'display': 'ParentsCaregivers', 'synonyms': ['parents', 'caregivers', 'ParentsCaregivers'], 'additional_context': None}}, 'ImmuneStatus': {'Immunocompromised': {'display': 'Immunocompromised', 'synonyms': ['immunocompromised', 'Immunocompromised'], 'additional_context': None}, 'Healthy': {'display': 'Healthy', 'synonyms': ['healthy', 'Healthy'], 'additional_context': None}}}, 'Topic': {'Efficacy-Effectiveness': {'Efficacy-Effectiveness': {'display': 'Efficacy-Effectiveness', 'synonyms': ['effectiveness', 'impact of', 'effectiveness of', 'efficacy', 'Efficacy-Effectiveness'], 'additional_context': None}}, 'Safety': {'Safety': {'display': 'Safety', 'synonyms': ['safety', 'adverse effects', 'adverse events', 'Safety'], 'additional_context': None}}, 'Risk-Factor': {'Risk-Factor': {'display': 'Risk-Factor', 'synonyms': ['risk factor', 'risk', 'Risk-Factor'], 'additional_context': None}}, 'Administration': {'Administration': {'display': 'Administration', 'synonyms': ['administration', 'vaccine types', 'dose schedules', 'vaccine types and dose schedules', 'different dose schedules', 'Two doses of', 'Administration'], 'additional_context': None}}, 'Economic-Aspects': {'Economic-Aspects': {'display': 'Economic-Aspects', 'synonyms': ['economic', 'cost', 'financial', 'economic impact', 'cost effectiveness', 'cost-effectiveness', 'cost', 'cost effectiveness', 'economic evaluation', 'Cost-effectiveness of HPV vaccination strategies', 'Economic-Aspects'], 'additional_context': None}}, 'Acceptance': {'Acceptance': {'display': 'Acceptance', 'synonyms': ['acceptance', 'Barrier', 'vaccine barriers', 'knowledge', 'vaccination willingness and intentions', 'HPV vaccine acceptability, acceptability', 'Awareness and knowledge', 'Awareness', 'facilitators of and barriers', 'awareness,knowledge, acceptability, and intention', 'knowledge and acceptability', 'knowledge and awareness', 'attitudes and beliefs', 'Knowledge and Attitude', 'attitude', 'knowledge, awareness, and attitude', 'Acceptance'], 'additional_context': None}}, 'Modeling': {'Modeling': {'display': 'Modeling', 'synonyms': ['modeling', 'Modeling'], 'additional_context': None}}, 'Ethical-Issues': {'Ethical-Issues': {'display': 'Ethical-Issues', 'synonyms': ['racial', 'ethnic', 'ethnic minority', 'racial minority', 'racial/ethnic', 'racial/ethnic minority', 'racial disparity', 'ethnic disparity', 'minority', 'minority population', 'Ethical-Issues'], 'additional_context': None}}, 'Coverage': {'Coverage': {'display': 'Coverage', 'synonyms': ['coverage', 'uptake', 'the uptake', 'actual uptake', 'vaccine uptake', 'Coverage'], 'additional_context': None}}}, 'Outcome': {'Infection': {'Infection': {'display': 'Infection', 'synonyms': ['infection', 'Infection'], 'additional_context': None}}, 'ICU': {'ICU': {'display': 'ICU', 'synonyms': ['ICU', 'intensive care unit', 'intensive care'], 'additional_context': None}}, 'Death': {'Death': {'display': 'Death', 'synonyms': ['death', 'mortality', 'overall mortality', 'cancer related mortality', 'on overall and cancer mortality', 'Death'], 'additional_context': None}}, 'Hospitalization': {'Hospitalization': {'display': 'Hospitalization', 'synonyms': ['hospitalization', 'Hospitalization'], 'additional_context': None}}}, 'Reviews': {'Reviews': {'review': {'display': 'review', 'synonyms': ['systematic review', 'Literature Review', 'review', 'Meta-Analysis', 'Critical Review', 'Peer Review', 'Book Review', 'Editorial Review', 'Review Article'], 'additional_context': None}}}, 'Studies': {'NoOfStudies': {'number_of_studies': {'display': 'number_of_studies', 'synonyms': ['studies', 'studies', 'number_of_studies'], 'additional_context': None}}, 'RCT': {'RCT_terms': {'display': 'RCT_terms', 'synonyms': ['brandomized controlled trial', 'RCT', 'brandomised controlled trial', 'brandomized trial', 'brandomised trial', 'RCT_terms'], 'additional_context': None}}}, 'Intervention': {'Vaccine-preventable-disease': {'COVID-19': {'display': 'COVID-19', 'synonyms': ['COVID-19', 'COVID', 'COVID 19'], 'additional_context': None}, 'Influenza': {'display': 'Influenza', 'synonyms': ['influenza', 'Influenza'], 'additional_context': None}, 'Dengue': {'display': 'Dengue', 'synonyms': ['dengue', 'Dengue'], 'additional_context': None}, 'Rotavirus': {'display': 'Rotavirus', 'synonyms': ['rotavirus', 'Rotavirus'], 'additional_context': None}}, 'Vaccine-Options': {'Live': {'display': 'Live', 'synonyms': ['live', 'Live'], 'additional_context': None}, 'Adjuvants': {'display': 'Adjuvants', 'synonyms': ['adjuvants', 'Adjuvants'], 'additional_context': None}, 'Non-Live': {'display': 'Non-Live', 'synonyms': ['non-live', 'Non-Live'], 'additional_context': None}}}}\n",
    "result = map_user_selection_to_column(user_selection, structured_data)\n",
    "print(f\"Result: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF content saved to extracted_pdf_content.txt, excluding references.\n",
      "HTML content saved to extracted_html_content.txt, excluding references.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "from bs4 import BeautifulSoup\n",
    "from PyPDF2 import PdfReader\n",
    "import requests\n",
    "\n",
    "class DocumentParser:\n",
    "    def __init__(self):\n",
    "        self.sections = defaultdict(dict)\n",
    "\n",
    "    def extract_text_from_html(self, html_content):\n",
    "        \"\"\"\n",
    "        Extracts and cleans text from an HTML document.\n",
    "        \"\"\"\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        text = soup.get_text(separator=\"\\n\")\n",
    "        return text.strip()\n",
    "\n",
    "    def extract_text_from_pdf(self, pdf_path):\n",
    "        \"\"\"\n",
    "        Extracts text from a PDF file using PyPDF2 with enhanced text normalization.\n",
    "        Handles multi-column layouts and embedded images more robustly.\n",
    "        \"\"\"\n",
    "        text = []\n",
    "        reader = PdfReader(pdf_path)\n",
    "        for page in reader.pages:\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:\n",
    "                # Normalize spaces and handle multi-column artifacts\n",
    "                cleaned_text = re.sub(r\"\\s+\", \" \", page_text).strip()\n",
    "                text.append(cleaned_text)\n",
    "            else:\n",
    "                text.append(\"[Page content could not be extracted]\")\n",
    "        return \"\\n\".join(text).strip()\n",
    "\n",
    "    def extract_text_from_url(self, url):\n",
    "        \"\"\"\n",
    "        Extracts text from a URL, handling both HTML and PDF resources.\n",
    "        \"\"\"\n",
    "        headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "        response = requests.get(url, headers=headers)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            content_type = response.headers.get(\"Content-Type\", \"\")\n",
    "            if \"text/html\" in content_type:\n",
    "                return self.extract_text_from_html(response.text)\n",
    "            elif \"application/pdf\" in content_type:\n",
    "                with open(\"temp.pdf\", \"wb\") as f:\n",
    "                    f.write(response.content)\n",
    "                return self.extract_text_from_pdf(\"temp.pdf\")\n",
    "        else:\n",
    "            raise ValueError(f\"Failed to fetch URL. Status code: {response.status_code}\")\n",
    "\n",
    "    def identify_sections_with_subsections(self, text):\n",
    "        \"\"\"\n",
    "        Dynamically identifies sections and their subsections in a document using flexible patterns.\n",
    "        \"\"\"\n",
    "        # Define regex patterns for sections and subsections\n",
    "        section_pattern = re.compile(r\"^(?:\\d+\\.\\s*)?(Abstract|Introduction|Methods|Materials|Data Collection|Results|Discussion|Conclusion|Acknowledgments|Appendix):?$\", re.IGNORECASE | re.MULTILINE)\n",
    "        subsection_pattern = re.compile(r\"^\\d+\\.\\d+\\s+[A-Za-z0-9 \\-]+:?\")\n",
    "\n",
    "        self.sections = defaultdict(dict)  # Reset sections\n",
    "        current_section = None\n",
    "        current_subsection = None\n",
    "\n",
    "        for line in text.split(\"\\n\"):\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "\n",
    "            # Match sections\n",
    "            section_match = section_pattern.match(line)\n",
    "            if section_match:\n",
    "                current_section = section_match.group(1).strip()\n",
    "                # Exclude \"References\" section explicitly\n",
    "                if \"reference\" not in current_section.lower():\n",
    "                    self.sections[current_section] = {\"content\": [], \"subsections\": {}}\n",
    "                current_subsection = None\n",
    "                continue\n",
    "\n",
    "            # Match subsections\n",
    "            subsection_match = subsection_pattern.match(line)\n",
    "            if subsection_match and current_section:\n",
    "                current_subsection = subsection_match.group(0).strip()\n",
    "                self.sections[current_section][\"subsections\"][current_subsection] = []\n",
    "                continue\n",
    "\n",
    "            # Append content to the appropriate section or subsection\n",
    "            if current_subsection:\n",
    "                self.sections[current_section][\"subsections\"][current_subsection].append(line)\n",
    "            elif current_section and \"reference\" not in current_section.lower():\n",
    "                self.sections[current_section][\"content\"].append(line)\n",
    "\n",
    "        # Combine subsection content\n",
    "        for section in self.sections:\n",
    "            for subsection in self.sections[section][\"subsections\"]:\n",
    "                self.sections[section][\"subsections\"][subsection] = \"\\n\".join(self.sections[section][\"subsections\"][subsection]).strip()\n",
    "            self.sections[section][\"content\"] = \"\\n\".join(self.sections[section][\"content\"]).strip()\n",
    "\n",
    "    def get_section_content(self, key):\n",
    "        \"\"\"\n",
    "        Retrieves content for a given section or subsection key.\n",
    "\n",
    "        Args:\n",
    "            key (str): The section or subsection key to retrieve content for.\n",
    "\n",
    "        Returns:\n",
    "            dict or str: The content of the section or subsection. If it has subsections, a dictionary is returned.\n",
    "        \"\"\"\n",
    "        # Check for top-level section\n",
    "        if key in self.sections:\n",
    "            return {\n",
    "                \"content\": self.sections[key][\"content\"],\n",
    "                \"subsections\": self.sections[key][\"subsections\"]\n",
    "            }\n",
    "\n",
    "        # Check for subsection\n",
    "        for section, details in self.sections.items():\n",
    "            if key in details[\"subsections\"]:\n",
    "                return details[\"subsections\"][key]\n",
    "\n",
    "        return None  # Key not found\n",
    "\n",
    "    def has_subsections(self, key):\n",
    "        \"\"\"\n",
    "        Checks if a given section has subsections.\n",
    "\n",
    "        Args:\n",
    "            key (str): The section key to check.\n",
    "\n",
    "        Returns:\n",
    "            bool: True if the section has subsections, False otherwise.\n",
    "        \"\"\"\n",
    "        if key in self.sections and self.sections[key][\"subsections\"]:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def get_all_section_content(self):\n",
    "        \"\"\"\n",
    "        Retrieves content of all sections and their subsections, excluding references.\n",
    "\n",
    "        Returns:\n",
    "            dict: A dictionary containing all sections and their content, excluding \"References\".\n",
    "        \"\"\"\n",
    "        all_content = {}\n",
    "        for section, details in self.sections.items():\n",
    "            if \"reference\" in section.lower():\n",
    "                continue\n",
    "            all_content[section] = {\n",
    "                \"content\": details[\"content\"],\n",
    "                \"subsections\": details[\"subsections\"]\n",
    "            }\n",
    "        return all_content\n",
    "\n",
    "    def save_content_to_file(self, content_dict, output_file):\n",
    "        \"\"\"\n",
    "        Save extracted content to a file, excluding sections named 'References' or similar.\n",
    "\n",
    "        Parameters:\n",
    "        - content_dict (dict): Dictionary with sections and subsections.\n",
    "        - output_file (str): Path to save the content.\n",
    "        \"\"\"\n",
    "        with open(output_file, \"w\", encoding=\"utf-8\") as file:\n",
    "            for section, content in content_dict.items():\n",
    "                file.write(f\"--- {section} ---\\n\")\n",
    "                file.write(\"Content:\\n\")\n",
    "                file.write(content[\"content\"] + \"\\n\")\n",
    "                file.write(\"Subsections:\\n\")\n",
    "                for subsection, subsection_content in content[\"subsections\"].items():\n",
    "                    file.write(f\"  - {subsection}: {subsection_content}\\n\")\n",
    "                file.write(\"\\n\")\n",
    "\n",
    "# Example usage\n",
    "parser = DocumentParser()\n",
    "\n",
    "# Test with a URL for a PDF\n",
    "pdf_url = \"https://pmc.ncbi.nlm.nih.gov/articles/PMC10278373/pdf/johm-8-S3-93.pdf\"\n",
    "pdf_text = parser.extract_text_from_url(pdf_url)\n",
    "parser.identify_sections_with_subsections(pdf_text)\n",
    "pdf_content = parser.get_all_section_content()\n",
    "parser.save_content_to_file(pdf_content, \"extracted_pdf_content.txt\")\n",
    "print(\"PDF content saved to extracted_pdf_content.txt, excluding references.\")\n",
    "\n",
    "# Test with a URL for HTML\n",
    "html_url = \"https://pmc.ncbi.nlm.nih.gov/articles/PMC10278373/\"\n",
    "html_text = parser.extract_text_from_url(html_url)\n",
    "parser.identify_sections_with_subsections(html_text)\n",
    "html_content = parser.get_all_section_content()\n",
    "parser.save_content_to_file(html_content, \"extracted_html_content.txt\")\n",
    "print(\"HTML content saved to extracted_html_content.txt, excluding references.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF content saved to extracted_content_pdf.txt.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "def save_content_to_file(content_dict, output_file):\n",
    "    \"\"\"\n",
    "    Save extracted content to a file, excluding sections named 'References' or similar.\n",
    "    \n",
    "    Parameters:\n",
    "    - content_dict (dict): Dictionary with sections and subsections.\n",
    "    - output_file (str): Path to save the content.\n",
    "    \"\"\"\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as file:\n",
    "        for section, content in content_dict.items():\n",
    "            # Skip sections named \"References\" or similar\n",
    "            if \"reference\" in section.lower():\n",
    "                continue\n",
    "            \n",
    "            file.write(f\"--- {section} ---\\n\")\n",
    "            file.write(\"Content:\\n\")\n",
    "            file.write(content[\"content\"] + \"\\n\")\n",
    "            file.write(\"Subsections:\\n\")\n",
    "            for subsection, subsection_content in content[\"subsections\"].items():\n",
    "                file.write(f\"  - {subsection}: {subsection_content}\\n\")\n",
    "            file.write(\"\\n\")\n",
    "\n",
    "def save_pdf_content_to_file(pdf_content, output_file):\n",
    "    \"\"\"\n",
    "    Save extracted PDF content to a file.\n",
    "    \n",
    "    Parameters:\n",
    "    - pdf_content (list): List of strings, one per page.\n",
    "    - output_file (str): Path to save the content.\n",
    "    \"\"\"\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as file:\n",
    "        for page_number, text in enumerate(pdf_content, start=1):\n",
    "            file.write(f\"--- Page {page_number} ---\\n\")\n",
    "            file.write(text + \"\\n\")\n",
    "\n",
    "def fetch_and_process_url(url):\n",
    "    \"\"\"\n",
    "    Fetch content from a URL, process based on content type (HTML or PDF),\n",
    "    and save extracted content to a file.\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        content_type = response.headers.get(\"Content-Type\", \"\")\n",
    "        \n",
    "        if \"text/html\" in content_type:\n",
    "            # Handle HTML content\n",
    "            html_content = response.text\n",
    "            parser = DocumentParser()\n",
    "\n",
    "            # Extract text from the HTML\n",
    "            document_text = parser.extract_text_from_html(html_content)\n",
    "            \n",
    "            # Identify sections and subsections\n",
    "            parser.identify_sections_with_subsections(document_text)\n",
    "            \n",
    "            # Retrieve all sections\n",
    "            all_content = parser.get_all_section_content()\n",
    "            \n",
    "            # Save content to a file\n",
    "            output_file = \"extracted_content_html.txt\"\n",
    "            save_content_to_file(all_content, output_file)\n",
    "            print(f\"HTML content saved to {output_file}, excluding references.\")\n",
    "\n",
    "        elif \"application/pdf\" in content_type:\n",
    "            # Handle PDF content using PyPDF2\n",
    "            output_file = \"extracted_content_pdf.txt\"\n",
    "            \n",
    "            with open(\"temp.pdf\", \"wb\") as temp_pdf:\n",
    "                temp_pdf.write(response.content)\n",
    "\n",
    "            reader = PdfReader(\"temp.pdf\")\n",
    "            pdf_content = [page.extract_text() for page in reader.pages]\n",
    "            \n",
    "            save_pdf_content_to_file(pdf_content, output_file)\n",
    "            print(f\"PDF content saved to {output_file}.\")\n",
    "        else:\n",
    "            print(\"Unsupported content type.\")\n",
    "    else:\n",
    "        print(f\"Failed to fetch the URL. Status code: {response.status_code}\")\n",
    "\n",
    "# Example usage\n",
    "url = \"https://pmc.ncbi.nlm.nih.gov/articles/PMC10278373/pdf/johm-8-S3-93.pdf\"  # Replace with your URL\n",
    "fetch_and_process_url(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\xef\\xbb\\xbf<!DOCTYPE html>\\r\\n<html lang=\"pt-br\">\\r\\n\\r\\n<head>\\r\\n<meta charset=\"utf-8\">\\r\\n  <meta http-equiv=\"x-ua-compatible\" content=\"ie=edge\">\\r\\n  <meta http-equiv=\"cache-control\" content=\"no-transform\" />\\r\\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1, minimum-scale=1\">\\r\\n\\r\\n  <!-- Google tag (gtag.js) --> <script async src=\"https://www.googletagmanager.com/gtag/js?id=G-YLYPPRQS7S\"></script> <script> window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag(\\'js\\', new Date()); gtag(\\'config\\', \\'G-YLYPPRQS7S\\'); </script>\\r\\n\\r\\n  <link rel=\"icon\" href=\"data:;base64,iVBORw0KGgo=\">\\r\\n  <link rel=\"stylesheet\" href=\"/css/global.css\">\\r\\n\\r\\n  <!--font awesome-->\\r\\n  <link rel=\"stylesheet\" href=\"/css/font-awesome/font-awesome.min.css\">\\r\\n\\r\\n  <base href=\"/\">\\r\\n\\r\\n</head>\\r\\n\\r\\n<body class=\"estado\">\\r\\n\\r\\n  <!-- Componente principal -->\\r\\n  <app></app>\\r\\n\\r\\n  <!-- integrity gerado por https://www.srihash.org/ -->\\r\\n  <!-- polyfills para funcionar no IE -->\\r\\n  <script src=\"https://cdnjs.cloudflare.com/ajax/libs/es5-shim/4.5.7/es5-shim.min.js\"></script>\\r\\n  <script src=\"https://cdnjs.cloudflare.com/ajax/libs/es5-shim/4.5.7/es5-sham.min.js\"></script>\\r\\n  <script src=\"https://cdnjs.cloudflare.com/ajax/libs/json3/3.3.2/json3.min.js\"></script>\\r\\n  <script src=\"https://cdnjs.cloudflare.com/ajax/libs/es6-shim/0.34.2/es6-shim.min.js\"></script>\\r\\n  <!-- -->\\r\\n\\r\\n  <!-- Chart.js -->\\r\\n  <script src=\"chart.bundle.min.js\"></script>\\r\\n\\r\\n  <!-- ANGULAR -->\\r\\n  <script src=\"/dist/vendor.js\"></script>\\r\\n  <script src=\"/dist/main-client.js\"></script>\\r\\n  <!-- -->\\r\\n\\r\\n  <!-- BARRA GOV.BR -->\\r\\n  <script defer=\"defer\" src=\"//barra.brasil.gov.br/barra_2.0.js\" type=\"text/javascript\"></script>\\r\\n  <!--  -->\\r\\n</body>\\r\\n\\r\\n</html>'\n",
      "Population data not found.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the webpage to scrape\n",
    "url = \"https://cidades.ibge.gov.br/brasil/se/aracaju/panorama\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    print(response.content)\n",
    "    # Extract specific information (e.g., population data)\n",
    "    # Adjust the selectors based on the webpage structure\n",
    "    population = soup.find('span', class_='population-number')  # Example selector\n",
    "    if population:\n",
    "        print(f\"Population: {population.text.strip()}\")\n",
    "    else:\n",
    "        print(\"Population data not found.\")\n",
    "else:\n",
    "    print(f\"Failed to retrieve the page. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sense-app",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
