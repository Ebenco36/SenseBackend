{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-b6e6c5cafe1f46dd95fb3eff444eae58.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-b6e6c5cafe1f46dd95fb3eff444eae58.vega-embed details,\n",
       "  #altair-viz-b6e6c5cafe1f46dd95fb3eff444eae58.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-b6e6c5cafe1f46dd95fb3eff444eae58\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-b6e6c5cafe1f46dd95fb3eff444eae58\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-b6e6c5cafe1f46dd95fb3eff444eae58\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.16.3?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.16.3\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"url\": \"https://cdn.jsdelivr.net/npm/vega-datasets@v1.29.0/data/world-110m.json\", \"format\": {\"feature\": \"countries\", \"type\": \"topojson\"}}, \"mark\": {\"type\": \"geoshape\"}, \"encoding\": {\"color\": {\"field\": \"value\", \"type\": \"quantitative\"}}, \"height\": 400, \"projection\": {\"type\": \"naturalEarth1\"}, \"transform\": [{\"lookup\": \"id\", \"from\": {\"data\": {\"name\": \"data-c70d2de02064273e9372d0f533db2483\"}, \"key\": \"id\", \"fields\": [\"value\"]}}, {\"calculate\": \"datum.value !== null ? datum.value : 0\", \"as\": \"value\"}], \"width\": 800, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.16.3.json\", \"datasets\": {\"data-c70d2de02064273e9372d0f533db2483\": [{\"id\": 840, \"country\": \"United States\", \"value\": 300}, {\"id\": 124, \"country\": \"Canada\", \"value\": 100}, {\"id\": 356, \"country\": \"India\", \"value\": 1200}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import altair as alt\n",
    "import pandas as pd\n",
    "from vega_datasets import data\n",
    "\n",
    "# Load TopoJSON countries\n",
    "countries = alt.topo_feature(data.world_110m.url, 'countries')\n",
    "\n",
    "# Your country data (using ISO numeric codes)\n",
    "source = pd.DataFrame({\n",
    "    'id': [840, 124, 356],  # USA, Canada, India\n",
    "    'country': ['United States', 'Canada', 'India'],\n",
    "    'value': [300, 100, 1200]\n",
    "})\n",
    "\n",
    "# Choropleth with fallback value\n",
    "choropleth = alt.Chart(countries).mark_geoshape().encode(\n",
    "    color='value:Q'\n",
    ").transform_lookup(\n",
    "    lookup='id',\n",
    "    from_=alt.LookupData(source, 'id', ['value'])\n",
    ").transform_calculate(\n",
    "    value=\"datum.value !== null ? datum.value : 0\"\n",
    ").project(\n",
    "    type='naturalEarth1'\n",
    ").properties(\n",
    "    width=800,\n",
    "    height=400\n",
    ")\n",
    "\n",
    "choropleth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total IDs retrieved for query: 0\n",
      "No results found for query.\n",
      "No data to save.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from src.api_utils import ilove_access, cochrane_access, medline_class_access, ovid_new_access\n",
    "\n",
    "medline_class_access(searchText=[\"\"\"\n",
    "(\n",
    "  (review[pt] OR \"review, tutorial\"[pt] OR \"review, academic\"[pt])\n",
    "  AND \n",
    "  (\n",
    "    medline[tw] OR medlars[tw] OR embase[tw] OR pubmed[tw] OR cochrane[tw]\n",
    "    OR scisearch[tw] OR psychinfo[tw] OR psycinfo[tw]\n",
    "    OR psychlit[tw] OR psyclit[tw] \n",
    "    OR cinahl[tw] \n",
    "    OR ((hand[tw] AND search*[tw]) OR (manual*[tw] AND search*[tw]))\n",
    "    OR (\"electronic database*\"[tw] OR \"bibliographic database*\"[tw] OR \"computerized database*\"[tw] OR \"online database*\"[tw])\n",
    "    OR pooling[tw] OR pooled[tw] OR \"mantel haenszel\"[tw]\n",
    "    OR peto[tw] OR dersimonian[tw] OR \"der simonian\"[tw] OR \"fixed effect\"[tw]\n",
    "    OR \"retraction of publication\"[pt] OR \"retracted publication\"[pt]\n",
    "  )\n",
    ")\n",
    "OR\n",
    "(\n",
    "  meta-analysis[pt] \n",
    "  OR meta-analysis[sh] \n",
    "  OR (meta-analys*[tw] OR meta analys*[tw] OR metaanalys*[tw])\n",
    "  OR (systematic*[tw] AND review*[tw])\n",
    "  OR (quantitative*[tw] AND review*[tw])\n",
    "  OR (methodologic*[tw] AND review*[tw])\n",
    "  OR (\"integrative research review\"[tw] OR \"research integration\"[tw])\n",
    ")\n",
    "AND\n",
    "(\n",
    "  immunization[mesh] \n",
    "  OR Immunization Programs[mesh] \n",
    "  OR vaccines[mesh]\n",
    "  OR (immunisation[tiab] OR immunization[tiab] OR immunise[tiab] OR immunize[tiab] OR vaccine[tiab])\n",
    ")\n",
    "AND humans[filter]\n",
    "AND \n",
    "(\"2011\"[edat] : \"3000\"[edat])\n",
    "\"\"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Executing PubMed search...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Retrieved 6997 IDs (total so far: 6997)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üì¶ Fetching details:  36%|‚ñà‚ñà‚ñà‚ñå      | 5/14 [00:26<00:48,  5.38s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    123\u001b[0m     QUERY \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    125\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(review[pt] OR \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mreview, tutorial\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m[pt] OR \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mreview, academic\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m[pt]) AND \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAND (\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m2011\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m[edat] : \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m3000\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m[edat])\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    147\u001b[0m )\n\u001b[1;32m    149\u001b[0m     fetcher \u001b[38;5;241m=\u001b[39m MedlineFetcher(email\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mebenco94@gmail.com\u001b[39m\u001b[38;5;124m\"\u001b[39m, api_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md4658719b8b55fb6817d221776bbddece608\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 150\u001b[0m     \u001b[43mfetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mQUERY\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36mMedlineFetcher.run\u001b[0;34m(self, query, output_csv)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚ö†Ô∏è No articles found for the query.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m records \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch_medline_records\u001b[49m\u001b[43m(\u001b[49m\u001b[43mid_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m records:\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚ö†Ô∏è No records could be fetched.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36mMedlineFetcher.fetch_medline_records\u001b[0;34m(self, id_list, batch_size)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     handle \u001b[38;5;241m=\u001b[39m Entrez\u001b[38;5;241m.\u001b[39mefetch(db\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpubmed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39mid_string, rettype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedline\u001b[39m\u001b[38;5;124m\"\u001b[39m, retmode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 55\u001b[0m     records \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(Medline\u001b[38;5;241m.\u001b[39mparse(StringIO(\u001b[43mhandle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)))\n\u001b[1;32m     56\u001b[0m     all_records\u001b[38;5;241m.\u001b[39mextend(records)\n\u001b[1;32m     57\u001b[0m     handle\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py:460\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunked:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_chunked\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[1;32m    464\u001b[0m         \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py:583\u001b[0m, in \u001b[0;36mHTTPResponse._read_chunked\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    582\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 583\u001b[0m         chunk_left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_chunk_left\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    584\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m chunk_left \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    585\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py:566\u001b[0m, in \u001b[0;36mHTTPResponse._get_chunk_left\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_safe_read(\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# toss the CRLF at the end of the chunk\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 566\u001b[0m     chunk_left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_next_chunk_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m IncompleteRead(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py:526\u001b[0m, in \u001b[0;36mHTTPResponse._read_next_chunk_size\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_next_chunk_size\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    525\u001b[0m     \u001b[38;5;66;03m# Read the next chunk size from the file\u001b[39;00m\n\u001b[0;32m--> 526\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    527\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    528\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchunk size\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/socket.py:717\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    716\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 717\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    718\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    719\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/ssl.py:1307\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1304\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1305\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1306\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1309\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.16/Frameworks/Python.framework/Versions/3.10/lib/python3.10/ssl.py:1163\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1161\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1163\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1164\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1165\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from Bio import Entrez, Medline\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "class MedlineFetcher:\n",
    "    def __init__(self, email, api_key=None):\n",
    "        Entrez.email = email\n",
    "        if api_key:\n",
    "            Entrez.api_key = api_key\n",
    "\n",
    "    def search_pubmed(self, query, retmax=10000):\n",
    "        \"\"\"Search PubMed with the given query and return all matching IDs.\"\"\"\n",
    "        all_ids = []\n",
    "        retstart = 0\n",
    "\n",
    "        print(\"üîç Executing PubMed search...\")\n",
    "        while True:\n",
    "            try:\n",
    "                handle = Entrez.esearch(\n",
    "                    db=\"pubmed\", term=query, retmax=retmax,\n",
    "                    retstart=retstart, usehistory=\"y\"\n",
    "                )\n",
    "                record = Entrez.read(handle)\n",
    "                handle.close()\n",
    "\n",
    "                ids = record.get(\"IdList\", [])\n",
    "                all_ids.extend(ids)\n",
    "\n",
    "                print(f\"üîπ Retrieved {len(ids)} IDs (total so far: {len(all_ids)})\")\n",
    "\n",
    "                if len(ids) < retmax:\n",
    "                    break\n",
    "\n",
    "                retstart += retmax\n",
    "                time.sleep(0.5)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error: {e}\")\n",
    "                break\n",
    "\n",
    "        return all_ids\n",
    "\n",
    "    def fetch_medline_records(self, id_list, batch_size=500):\n",
    "        \"\"\"Fetch MEDLINE records for a list of PubMed IDs.\"\"\"\n",
    "        all_records = []\n",
    "\n",
    "        for start in tqdm(range(0, len(id_list), batch_size), desc=\"üì¶ Fetching details\"):\n",
    "            batch_ids = id_list[start:start + batch_size]\n",
    "            id_string = \",\".join(batch_ids)\n",
    "\n",
    "            try:\n",
    "                handle = Entrez.efetch(db=\"pubmed\", id=id_string, rettype=\"medline\", retmode=\"text\")\n",
    "                records = list(Medline.parse(StringIO(handle.read())))\n",
    "                all_records.extend(records)\n",
    "                handle.close()\n",
    "                time.sleep(0.5)\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error in batch {start}: {e}\")\n",
    "\n",
    "        print(f\"‚úÖ Total MEDLINE records fetched: {len(all_records)}\")\n",
    "        return all_records\n",
    "\n",
    "    def clean_doi(self, doi_list):\n",
    "        \"\"\"Clean and join DOIs if present in AID field.\"\"\"\n",
    "        return \"; \".join([d.split()[0] for d in doi_list if \"doi\" in d.lower()])\n",
    "\n",
    "    def process_records(self, records):\n",
    "        \"\"\"Convert MEDLINE records to DataFrame and filter Systematic Reviews/Meta-analyses.\"\"\"\n",
    "        print(\"üßπ Cleaning and structuring records...\")\n",
    "        data = []\n",
    "        for rec in records:\n",
    "            doi = self.clean_doi(rec.get(\"AID\", []))\n",
    "            publication_type = \"; \".join(rec.get(\"PT\", []))\n",
    "\n",
    "            data.append({\n",
    "                \"pmid\": rec.get(\"PMID\", \"\"),\n",
    "                \"title\": rec.get(\"TI\", \"\"),\n",
    "                \"abstract\": rec.get(\"AB\", \"\"),\n",
    "                \"authors\": \"; \".join(rec.get(\"AU\", [])),\n",
    "                \"publication_date\": rec.get(\"DP\", \"\"),\n",
    "                \"journal\": rec.get(\"JT\", \"\"),\n",
    "                \"country\": rec.get(\"PL\", \"\"),\n",
    "                \"language\": \"; \".join(rec.get(\"LA\", [])),\n",
    "                \"mesh_terms\": \"; \".join(rec.get(\"MH\", [])),\n",
    "                \"publication_type\": publication_type,\n",
    "                \"doi\": doi\n",
    "            })\n",
    "\n",
    "        df = pd.DataFrame(data)\n",
    "        df['publication_type'] = df['publication_type'].astype(str)\n",
    "\n",
    "        # Filter by publication_type\n",
    "        df = df[\n",
    "            df['publication_type'].str.contains(\"Systematic Review|Meta-Analysis\", case=False, na=False)\n",
    "        ]\n",
    "\n",
    "        df['year'] = pd.to_datetime(df['publication_date'], errors='coerce').dt.year\n",
    "        df.drop_duplicates(subset='pmid', inplace=True)\n",
    "        return df\n",
    "\n",
    "    def run(self, query, output_csv=\"medline_filtered_output.csv\"):\n",
    "        id_list = self.search_pubmed(query)\n",
    "        if not id_list:\n",
    "            print(\"‚ö†Ô∏è No articles found for the query.\")\n",
    "            return\n",
    "\n",
    "        records = self.fetch_medline_records(id_list)\n",
    "        if not records:\n",
    "            print(\"‚ö†Ô∏è No records could be fetched.\")\n",
    "            return\n",
    "\n",
    "        df = self.process_records(records)\n",
    "        if df.empty:\n",
    "            print(\"‚ö†Ô∏è No records matched the filter for publication_type.\")\n",
    "        else:\n",
    "            df.to_csv(output_csv, index=False)\n",
    "            print(f\"üìÅ Saved {len(df)} filtered records to: {output_csv}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    QUERY = (\n",
    "    \"(\"\n",
    "        \"(review[pt] OR \\\"review, tutorial\\\"[pt] OR \\\"review, academic\\\"[pt]) AND \"\n",
    "        \"(\"\n",
    "            \"medline[tw] OR medlars[tw] OR embase[tw] OR pubmed[tw] OR cochrane[tw] OR \"\n",
    "            \"scisearch[tw] OR psychinfo[tw] OR psycinfo[tw] OR psychlit[tw] OR psyclit[tw] OR \"\n",
    "            \"cinahl[tw] OR ((hand[tw] AND search*[tw]) OR (manual*[tw] AND search*[tw])) OR \"\n",
    "            \"\\\"electronic database*\\\"[tw] OR \\\"bibliographic database*\\\"[tw] OR \\\"computerized database*\\\"[tw] OR \\\"online database*\\\"[tw] OR \"\n",
    "            \"pooling[tw] OR pooled[tw] OR \\\"mantel haenszel\\\"[tw] OR peto[tw] OR dersimonian[tw] OR \\\"der simonian\\\"[tw] OR \\\"fixed effect\\\"[tw] OR \"\n",
    "            \"\\\"retraction of publication\\\"[pt] OR \\\"retracted publication\\\"[pt]\"\n",
    "        \")\"\n",
    "    \") \"\n",
    "    \"OR \"\n",
    "    \"(\"\n",
    "        \"meta-analysis[pt] OR meta-analysis[sh] OR meta-analys*[tw] OR meta analys*[tw] OR metaanalys*[tw] OR \"\n",
    "        \"(systematic*[tw] AND review*[tw]) OR (quantitative*[tw] AND review*[tw]) OR \"\n",
    "        \"(methodologic*[tw] AND review*[tw]) OR \\\"integrative research review\\\"[tw] OR \\\"research integration\\\"[tw]\"\n",
    "    \") \"\n",
    "    \"AND (\"\n",
    "        \"immunization[mesh] OR Immunization Programs[mesh] OR vaccines[mesh] OR \"\n",
    "        \"immunisation[tiab] OR immunization[tiab] OR immunise[tiab] OR immunize[tiab] OR vaccine[tiab]\"\n",
    "    \") \"\n",
    "    \"AND humans[filter] \"\n",
    "    \"AND (\\\"2011\\\"[edat] : \\\"3000\\\"[edat])\"\n",
    ")\n",
    "\n",
    "    fetcher = MedlineFetcher(email=\"ebenco94@gmail.com\", api_key=\"d4658719b8b55fb6817d221776bbddece608\")\n",
    "    fetcher.run(QUERY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".sense",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
